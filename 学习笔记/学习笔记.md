## 总体思路:
用Huggingface的EncoderDecoderModel写个bert2bert

### 1. utils数据处理
把小说根据段落拆开，用上一段续写下一段  
> dataset返回的inputs要带上labels
#### data_collator
> data_collator = DataCollatorForSeq2Seq(tokenizer, model)  
> 可以自动对数据做batch，传入Dataloader的collate_fn

### 2. model改写模型
```python
bert2bert = EncoderDecoderModel.from_encoder_decoder_pretrained(
    "src/bert-base-chinese", "src/bert-base-chinese")
```
> forward的参数要写好，源码中根据model.forward的参数提取dataset(dict)的key，不在forward参数里的会被剔除掉
#### 锁层与解锁
```python
    def freeze(self):
        for pn, p in self.named_parameters():
            if not re.search('crossattention', pn):
                p.requires_grad = False

    def in_freeze(self):
        for pn, p in self.named_parameters():
            if not re.search('crossattention', pn):
                p.requires_grad = True
```

### 3.trainer
原本的trainer还是可以用
这里用包里的Seq2SeqTrainer
#### args
参数
* output_dir 模型保存路径
* evaluation_strategy="no"
*    save_strategy="epoch" 保存频率
*    learning_rate=lr_init 学习率
*    per_device_train_batch_size=batch_size
*    per_device_eval_batch_size=2
*    weight_decay=0.01
*    save_total_limit=3 最大保存次数
*    num_train_epochs=3 最大迭代轮次
*    fp16=True 设置半精度

#### Trainer
参数
*    model 模型
*    args  上面的args
*    train_dataset=train_set 训练集
*    eval_dataset  测试集/可选
*    data_collator=data_collator
*    tokenizer=tokenizer


## 租服务器
### ssh
`ssh一定要公网IP`
#### 安装 openssh
`sudo apt-get install openssh-server`
#### 下面生成公钥和私钥，在普通用户下：
`ssh-keygen -t rsa ← 建立公钥与私钥`
* 复制 id_rsa 到 windows 的机器上。
* 使用 PUTTYGEN.EXE 转换成 putty 可以使用的。
* 打开 PUTTYGEN.EXE ，点击 Load，选取服务器端生成的私钥。
* 点击 “Save private key”，保存为 .ppk 文件，这里是 uServer.ppk


* 在 putty 中使用转换后的私钥登录。
* 打开 putty.exe ，设置好 IP，然后在 Connection - SSH - Auth 的 Private key file for authentication 中选择 uServer.ppk。

## ubuntu
* **复制**
```
cp [src-file] [target-file]
# 文件夹下还有文件用-r递归
cp -r [src-file] [target-file]
```
* **移动**
```
sudo mv [src-file] [target-file]
```
* **安装东西**
```
sudo apt-get install [name]
# 安装python
sudo apt-get python3-pip
```

## 实验
复读机

### 数据集用单用2段话续写后面一段
```python
epoch = 2
lr = 2e-5
loss = 2.9787
```
>[CLS] 第 1 章 你 好 ， 叶 修 ！ [SEP] 第 1 章 你 好 ， 叶 修 ！ [SEP] 现 在 你 有 三 个 选 择 。 [SEP] 选 择 1 ： 立 刻 进 入 轮 回 ， 重 新 投 胎 ， 50 % 的 几 率 投 胎 人 道 ， 并 出 生 富 贵 家 庭 ， 一 辈 子 衣 食 无 忧 ； 同 样 50 % 的 几 率 入 牲 畜 道 ， 百 世 轮 回 ， 皆 为 牲 畜 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]  
>选 择 2 ： 穿 越 异 世 大 陆 ， 一 出 生 就 举 世 无 敌 ， 但 长 相 奇 丑 ， 命 运 坎 坷 ， 一 生 在 打 打 杀 杀 ， 勾 心 斗 角 中 度 过 ， 注 定 孤 独 终 老 。 [SEP] 选 择 3 ： 原 地 重 生 ， 激 活 任 务 系 统 ， 虽 然 你 资 质 依 然 极 差 ， 但 任 务 系 统 可 以 助 你 觉 醒 天 赋 ， 完 成 梦 想 ， 成 为 一 名 顶 尖 的 职 业 选 手 。 [SEP] 请 选 择 。 [SEP] 听 到 脑 海 中 的 声 音 ， 段 煜 有 些 没 反 应 过 来 。 [SEP] 这 是 地 狱 ， 还 是 天 堂 ？ [SEP] 自 己 不 是 被 车 撞 飞 了 吗 ？ [SEP] 人 死 后 ， 还 要 做 选 择 题 吗 ？ [SEP] 那 个 声 音 再 次 响 起 ： 选 择 倒 计 时 1098 [SEP]  
>[CLS] 当 然 ， 这 个 任 务 的 难 度 也 不 会 超 过 这 个 任 务 的 难 度 ， 毕 竟 ， 这 个 任 务 的 难 度 是 非 常 之 高 的 ， 而 且 ， 这 个 任 务 的 难 度 是 非 常 之 高 的 。 而 且 ， 这 个 任 务 的 难 度 非 常 之 高 ， 并 且 ， 任 务 完 成 之 后 ， 任 务 就 会 自 动 恢 复 为 正 常 状 态 ， 并 且 ， 任 务 完 成 之 后 ， 任 务 将 会 自 动 恢 复 为 正 常 状 态 ， 也 就 是 说 ， 任 务 完 成 之 后 ， 任 务 将 会 自 动 恢 复 为 正 常 状 态 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。

### 更换生成策略后
>[CLS] " 啪 ！ " 那 人 ， 大 喝 一 声 ， 冲 着 一 大 群 法 师 纷 纷 飞 奔 过 去 ， 其 中 一 个 高 高 举 着 斗 篷 的 人 正 在 躲 避 ， 他 目 光 一 扫 ， 似 乎 有 什 么 意 外 的 。 " 前 辈 ， 你 们 两 个 去 哪 ？ " 我 哈 哈 一 笑 ， " 前 辈 ， 我 们 去 看 看 一 下 ？ " 何 艺 问 道 。 " 这 次 ， 咱 们 不 用 寻 找 远 方 的 ， 是 不 是 ？ " 何 艺 微 微 笑 了 ， 随 后 将 后 面 的 队 伍 直 接 拉 开 ， 大 喝 一 声 ： " 我 们 在 这 里 ， 这 个 队 伍 ， 你 们 就 不 用 担 心 ！ " [SEP]


## generate
### [generationConfig参数](https://blog.csdn.net/Komach/article/details/129086525)
* **max_length** ：即限定生成的最大长度，这里的长度指的token的长度。并且是最大的长度，在这个长度之内的其他长度的句子也是可以被生成的。
* **do_sample**：do_sample是一个布尔值，是指是否使用采样（sampling）方法来生成文本。采样是一种生成文本的方法，它从模型输出的概率分布中随机采样一个 token 作为下一个生成的 token，具有一定的随机性和多样性，因此生成的文本可能更加多样化，而不是完全按照概率分布中的概率来选择下一个 token。
具体来说，如果设置 do_sample=True，那么在生成文本时就会使用采样方法。在采样时可以指定一些参数，例如 temperature、top_p 等，这些参数会影响采样方法的结果，从而影响生成文本的多样性和质量。
如果设置 do_sample=False，那么就会使用贪心算法（greedy decoding）来生成文本，即每次选择模型输出概率最大的 token 作为下一个 token，这种方法生成的文本可能会比较单一和呆板。
do_sample的设置影响后续一些参数的设置，有些并不能兼容使用。
* **num_beams** ：“num_beams"是在进行文本生成时的一个参数。它是指在生成一个序列的时候，预测模型同时生成的候选解的数量。在Beam Search生成文本的方法中，预测模型会对于每一个时间步，生成一定数量的候选解，选取其中最优解进行下一步预测，直到完成整个序列的生成。这个数量即为"num_beams”。
"num_beams"设置较高，可以增加生成的候选解的数量，从而得到更多可能性，但是会同时增加计算代价。因此，通常需要根据任务的需求，合理选择"num_beams"的值。
* **top_k** ：用于top-k筛选的最高概率词汇表标记的数量。
* **top_p**：“top_p” 是一个用于限制生成文本中词语选择的概率分布的参数。它代表了仅选择概率分布中前p%大的词语，而舍弃剩余的词语。通俗地说，它用于约束生成文本中词语的数量，防止生成过多的词语，并且只选择最可能的词语。
具体地，假设我们有一个模型，它预测了下一个单词的概率分布，如果我们将 top_p 设置为0.9，那么我们将只选择概率分布中前 90% 的词语。因此，如果我们生成的词语不在前90%，那么将不会考虑这个词语。这样做可以降低生成的词语数量，同时可以保证生成的词语更可能是正确的。
* **no_repeat_ngram_size**：no_repeat_ngram_size 参数指定了生成文本时需要避免的重复文本的大小。该参数指示在生成的文本中，最多允许多少个词与原始文本中的词进行重复。如果该值设置为 3，则生成的文本中的任何一段长度为三个词的子序列都不能与原始文本的任何子序列重复。设置该值可以防止生成的文本中出现重复词汇，因此可以提高生成文本的多样性。

### [生成策略](https://zhuanlan.zhihu.com/p/634369249)
#### 贪心（Greedy Search）
“直接选概率最大的词”
#### 束搜索（Beam Search）
它的基本思想是：在每一个时间步t，都保留多个不同的候选结果，直到最后一步才确定到底哪一个候选结果更为占优
#### Multinomial Sampling
它的基本思想是：在生成下一个候选词时，选定一个采样范围进行随机采样，在采样范围的词只要概率不为0，就有可能采样到这个词。在transformers库中，只需要设置num_beams=1且do_sample=True，就会进入Multinomial Sampling策略，  
`outputs = model.generate(**inputs, do_sample=True, num_beams=1)`
#### Top-K Sampling
Top-K Sampling的思路为：当要生成下一个词的时候，只截断选取概率最高的前K个词，对这K个词的概率重新进行归一化，然后在其中进行采样。   
`outputs = model.generate(**inputs, do_sample=True, num_beams=1, top_k=5)`
#### Top-P(nucleus) Sampling
在transformers中使用Top-P Sampling的方法如下（需要设置top_k=0来禁用Top-K Sampling）  
`outputs = model.generate(**inputs, do_sample=True, num_beams=1, top_p=0.5, top_k=0)`